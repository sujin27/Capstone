{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujinee01/Capstone/blob/main/TCNmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError:\n",
        "    !pip install pytorch-lightning\n",
        "#라이브러리 import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch1\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import drive\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "data = pd.read_excel(\"/content/drive/My Drive/LiFePO4 Dynamic Profile Files/LiFePO4 Dynamic Profile Files/-10도/LiFePO4_DST_SOC_N10_1.xlsx\")\n",
        "\n",
        "# 데이터 선택 (스케일링 전)\n",
        "data_selected = data.loc[:, [\"Current(A)\", \"Voltage(V)\", \"Temperature (C)_1\"]].copy()  # 헤더 포함한 전체 데이터 선택\n",
        "soc_data = data.loc[:,[\"SOC(t)\"]].copy()  # 헤더 포함한 전체 데이터 선택\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data_selected)\n",
        "\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=[\"Current(A)\", \"Voltage(V)\", \"Temperature (C)_1\"])\n",
        "\n",
        "\n",
        "# 테스트 데이터 비율 설정\n",
        "test_size = 0.2\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_scaled, soc_data.values, test_size=0.2, random_state=42)\n",
        "\n",
        "#TCN 모델\n",
        "class TCN(pl.LightningModule):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(input_size, tuple):\n",
        "            in_channels = input_size[0]\n",
        "        else:\n",
        "            in_channels = input_size\n",
        "\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=in_channels, out_channels=num_channels, kernel_size=kernel_size, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, kernel_size=kernel_size, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "        ])\n",
        "\n",
        "        self.linear_layer = nn.Linear(in_features=num_channels, out_features=output_size)\n",
        "\n",
        "        # 옵티마이저 정의\n",
        "        self.optimizer = torch.optim.Adam(self.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, conv_layer in enumerate(self.conv_layers):\n",
        "            x = conv_layer(x)\n",
        "            if i % 2 == 1:  # ReLU layer\n",
        "                x = x.detach()\n",
        "\n",
        "        x = x.mean(dim=2)\n",
        "\n",
        "        x = self.linear_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    # 학습 단계 정의 (수정)\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # 데이터 로더에서 받은 데이터 분리\n",
        "        x, y = batch\n",
        "\n",
        "        # 모델 예측\n",
        "        logits = self(x).squeeze()\n",
        "\n",
        "        # 손실 계산 (이진 분류 문제이므로 BCE 손실 함수 사용)\n",
        "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
        "\n",
        "        # 로그 기록\n",
        "        self.log(\"train_loss\", loss)\n",
        "\n",
        "        # 최적화 알고리즘 업데이트\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)  # 그래프 보존 설정\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    # 최적화 알고리즘 설정 (수정)\n",
        "    def configure_optimizers(self):\n",
        "        # 옵티마이저 반환\n",
        "        return self.optimizer\n",
        "\n",
        "\n",
        "\n",
        "# 모델 하이퍼파라미터 설정\n",
        "input_size = 3\n",
        "output_size = 1\n",
        "num_channels = 16\n",
        "kernel_size = 3\n",
        "\n",
        "# 모델 생성\n",
        "model = TCN(input_size, output_size, num_channels, kernel_size)\n",
        "\n",
        "# 학습률 및 에포크 수 설정\n",
        "lr = 0.001\n",
        "epochs = 100\n",
        "\n",
        "# Trainer 정의\n",
        "trainer = pl.Trainer(\n",
        "    default_root_dir=\"/content/drive/My Drive/LiFePO4 Dynamic Profile Files\",\n",
        "    max_epochs=epochs,\n",
        "    accelerator=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataset = [(torch.tensor(x).unsqueeze(1).float(), torch.tensor(y).float().squeeze()) for x, y in zip(X_train.values, y_train)]\n",
        "test_dataset = [(torch.tensor(x).unsqueeze(1).float(), torch.tensor(y).float().squeeze()) for x, y in zip(X_test.values, y_test)]\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "\n",
        "trainer.fit(model, train_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "# 모델의 예측값 계산\n",
        "model.eval()  # 모델을 평가 모드로 설정\n",
        "predictions = []\n",
        "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
        "    for inputs, labels in test_dataloader:\n",
        "        outputs = model(inputs)\n",
        "        predictions.extend(outputs.squeeze().tolist())\n",
        "\n",
        "# 예측값과 실제값의 MSE 및 RMSE 계산\n",
        "mse = nn.MSELoss()(torch.tensor(predictions), torch.tensor(y_test))\n",
        "rmse = torch.sqrt(mse)\n",
        "\n",
        "print(\"MSE:\", mse.item())\n",
        "print(\"RMSE:\", rmse.item())\n",
        "\n"
      ],
      "metadata": {
        "id": "xD2TrPKjxAll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3088f613-a311-46c0-d950-005e7292f512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Using cached pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Using cached torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.10.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Using cached lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.13.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch1'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-37d86d886dec>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch1'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRwZLEhY4Ip5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}