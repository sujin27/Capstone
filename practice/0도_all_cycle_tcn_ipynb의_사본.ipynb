{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujinee01/Capstone/blob/main/0%EB%8F%84_all_cycle_tcn_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAW_ln9KHYUg"
      },
      "source": [
        "# **0. 라이브러리**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj48OEHvHbgr",
        "outputId": "cd9c2621-e5b5-49ea-a157-13041d088723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "lZ2RCOCIveCe"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Min-Max 스케일러 인스턴스 생성\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgx6Pc3HDfVI"
      },
      "source": [
        "# **1. 데이터 정제**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cLp7sl4EBBQ"
      },
      "source": [
        "결측치 처리, 이상치 제거, 데이터 타입 변환 등 데이터를 분석에 적합한 형태로 정제합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "g1qyLxA9bwJ4"
      },
      "outputs": [],
      "source": [
        "# 데이터 정제 함수\n",
        "def preprocess_excel(file_path):\n",
        "    # 엑셀 파일 로드\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # 불필요한 열 제거\n",
        "    df.drop(columns=['Step_Time(s)','Step_Index','Unnamed: 7','Unnamed: 8','Unnamed: 9','Unnamed: 10'], inplace=True)\n",
        "\n",
        "    # 결측치가 있는 행 제거\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "6_b1heJQgYR6"
      },
      "outputs": [],
      "source": [
        "# Driving_Cycle 특성 추가 함수\n",
        "import re\n",
        "\n",
        "#파일 이름에서 정보 추출하는 함수 정의\n",
        "def extract_info_from_filename(filename):\n",
        "    # Driving Cycle과 온도 정보를 추출하는 정규 표현식\n",
        "    pattern = r'LiFePO4_(\\w+)_SOC_(-?\\d+)_'\n",
        "    match = re.search(pattern, filename)\n",
        "    if match:\n",
        "        Driving_Cycle = match.group(1)\n",
        "        temperature = int(match.group(2))\n",
        "        return Driving_Cycle, temperature\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Driving_Cycle을 정수형으로 반환하는 함수\n",
        "def Driving_Cycle_Numb(Driving_Cycle):\n",
        "  if Driving_Cycle=='DST':\n",
        "    Numb=1\n",
        "    return Numb\n",
        "  elif Driving_Cycle=='FUDS':\n",
        "    Numb=2\n",
        "    return Numb\n",
        "  elif Driving_Cycle=='US06':\n",
        "    Numb=3\n",
        "    return Numb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7-IYjcO_c92Q"
      },
      "outputs": [],
      "source": [
        "def process_all_files(folder_path):\n",
        "    # 모든 엑셀 파일 목록 가져오기\n",
        "    file_names = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
        "\n",
        "    # 파일 목록을 원하는 순서로 정렬\n",
        "\n",
        "    # 모든 파일에 대해 전처리 수행\n",
        "    processed_dfs = []\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # 불필요한 열, 결측치 행 제거\n",
        "        processed_df = preprocess_excel(file_path)\n",
        "\n",
        "        # 차분 : 비정상 시계열 -> 정상시계열\n",
        "        result = adfuller(processed_df['SOC(t)'])\n",
        "        processed_df['SOC(t)_diff'] = processed_df['SOC(t)'].diff()\n",
        "        processed_df['SOC(t)_diff'][0]=processed_df['SOC(t)_diff'][1] # NaN 값 대체\n",
        "\n",
        "        # 주행 사이클, 온도 열 추가\n",
        "        Driving_Cycle, temperature = extract_info_from_filename(file_name)\n",
        "        processed_df['Driving_Cycle']= Driving_Cycle_Numb(Driving_Cycle)\n",
        "\n",
        "        processed_dfs.append(processed_df)\n",
        "\n",
        "    return processed_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "M_1Qr-cwdOvu"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/LiFePO4 Dynamic Profile Files/LiFePO4 Dynamic Profile Files'\n",
        "all_processed_data = process_all_files(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLGN9Jhhd23z",
        "outputId": "1e3faba0-cd67-491f-82bc-e19c9a00144d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "all_processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIJgmwXhC7NY",
        "outputId": "49b77357-a707-4bf1-bb3f-6bf283c3ec9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "type(all_processed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19egfQo-EOG0"
      },
      "source": [
        "# **3. 특성 엔지니어링 및 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uncg7xrDqxk"
      },
      "source": [
        "# **2. 탐색적 데이터 분석(EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LCq6fnHDwX5"
      },
      "source": [
        "**-시각화** : 시계열 데이터의 추세(trend), 계절성(seasonality), 순환성(cyclic) 등을 파악하기 위해 시각화를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "QMjvGDgiCkeU",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 시각화를 위한 데이터 준비\n",
        "i=1\n",
        "for df in all_processed_data:\n",
        "  time_column = df['Test_Time(s)']\n",
        "  current = df['Current(A)']\n",
        "  voltage = df['Voltage(V)']\n",
        "  temperature = df['Temperature (C)_1']\n",
        "  soc_diff = df['SOC(t)_diff']\n",
        "  soc = df['SOC(t)']\n",
        "\n",
        "  # 각 값에 대한 시간 변화를 선 그래프로 시각화\n",
        "  plt.figure(figsize=(20, 10))\n",
        "\n",
        "  plt.subplot(6, 5, i)\n",
        "  plt.plot(time_column, current, label='Current(A)')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Current (A)')\n",
        "  plt.title('Current over Time')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(6, 5, i+1)\n",
        "  plt.plot(time_column, voltage, label='Voltage(V)', color='orange')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Voltage (V)')\n",
        "  plt.title('Voltage over Time')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(6, 5, i+2)\n",
        "  plt.plot(time_column, temperature, label='Temperature (C)', color='green')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Temperature (C)')\n",
        "  plt.title('Temperature over Time')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(6, 5, i+3)\n",
        "  plt.plot(time_column, soc_diff, label='SOC(t)_diff', color='red')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('SOC_diff (%)')\n",
        "  plt.title('SOC_diff over Time')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(6, 5, i+4)\n",
        "  plt.plot(time_column, soc, label='SOC(t)', color='red')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('SOC(t) (%)')\n",
        "  plt.title('SOC(t) over Time')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  i=i+5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdcW_3wXD5Vb"
      },
      "source": [
        "**-통계 분석** : 데이터의 통계적 속성을 분석합니다(예: 평균, 중앙값, 표준편차 등)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmyKzLiyEbdm"
      },
      "source": [
        "**-데이터 분할** : 모델 학습을 위해 데이터를 훈련 세트와 테스트 세트로 분할합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "sjVt1ywlsHnp"
      },
      "outputs": [],
      "source": [
        "# 데이터 분할\n",
        "\n",
        "# 특성과 타겟을 분리하는 함수\n",
        "def split_features_targets(df):\n",
        "    features = df[['Test_Time(s)', 'Current(A)', 'Voltage(V)', 'Temperature (C)_1', 'Driving_Cycle']]\n",
        "    targets = df['SOC(t)']\n",
        "    return features, targets\n",
        "\n",
        "# 전체 데이터셋에서 특성과 타겟 분리\n",
        "features_targets = [split_features_targets(df) for df in all_processed_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt390kwo3D-U",
        "outputId": "5a426c15-bb54-4faa-9131-26ae30613493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(features_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoDmwkx44pJf",
        "outputId": "266f844b-3e0d-4358-a0b3-05cf4013bdea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set Size: 0\n",
            "Validation Set Size: 0\n",
            "Test Set Size: 0\n"
          ]
        }
      ],
      "source": [
        "# train/validation/test split\n",
        "\n",
        "train_set = features_targets[1:6:2]\n",
        "validation_set = features_targets[2:5:2]\n",
        "test_set = features_targets[5:]\n",
        "\n",
        "# 각 세트의 크기 확인\n",
        "print(f\"Train Set Size: {len(train_set)}\")\n",
        "print(f\"Validation Set Size: {len(validation_set)}\")\n",
        "print(f\"Test Set Size: {len(test_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPo6h4yz4Yyr",
        "outputId": "fe18745f-47d3-4df9-c9a0-f0b6990a22b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_set\n",
            "[]\n",
            "Validation_set\n",
            "[]\n",
            "Test_set\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# 결과 출력\n",
        "print('Train_set')\n",
        "print(train_set)\n",
        "print('Validation_set')\n",
        "print(validation_set)\n",
        "print('Test_set')\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Z51VEpr-U06I"
      },
      "outputs": [],
      "source": [
        "# MinMax Scailing\n",
        "\n",
        "# 특성과 타겟을 위한 별도의 스케일러 생성\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "# Train 데이터에 스케일링 fit 및 transform 적용\n",
        "scaled_train_set = []\n",
        "for features, targets in train_set:\n",
        "    scaled_features = pd.DataFrame(feature_scaler.fit_transform(features), columns=features.columns, index=features.index)\n",
        "    scaled_targets = pd.Series(target_scaler.fit_transform(targets.values.reshape(-1, 1)).flatten(), index=targets.index)\n",
        "    scaled_train_set.append((scaled_features, scaled_targets))\n",
        "\n",
        "# Validation 및 Test 데이터에 스케일링 transform 적용\n",
        "def apply_transform(data_set, feature_scaler, target_scaler):\n",
        "    transformed_data_set = []\n",
        "    for features, targets in data_set:\n",
        "        transformed_features = pd.DataFrame(feature_scaler.transform(features), columns=features.columns, index=features.index)\n",
        "        transformed_targets = pd.Series(target_scaler.transform(targets.values.reshape(-1, 1)).flatten(), index=targets.index)\n",
        "        transformed_data_set.append((transformed_features, transformed_targets))\n",
        "    return transformed_data_set\n",
        "\n",
        "scaled_validation_set = apply_transform(validation_set, feature_scaler, target_scaler)\n",
        "scaled_test_set = apply_transform(test_set, feature_scaler, target_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyhn8_n-O0lq",
        "outputId": "f279fbc3-6879-40e7-af0e-589e4d2187bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled_train_set\n",
            " []\n",
            "Scaled_validation_set\n",
            " []\n",
            "Scaled_test_set\n",
            " []\n"
          ]
        }
      ],
      "source": [
        "print('Scaled_train_set\\n', scaled_train_set)\n",
        "print('Scaled_validation_set\\n', scaled_validation_set)\n",
        "print('Scaled_test_set\\n', scaled_test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20X9T7FXQHUs"
      },
      "source": [
        "Driving_Cycle은 범주형 변수이므로 원-핫 인코딩을 적용하는 것이 적절하다. 바꿔야함!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-La_C3CPEepP"
      },
      "source": [
        "# **4. 모델 선택 및 학습**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErlJCmBHEjAX"
      },
      "source": [
        "**-모델 선택**: ARIMA, SARIMA, Prophet, LSTM, GRU, TCN 등과 같은 다양한 시계열 예측 모델 중 프로젝트 목표와 데이터 특성에 맞는 모델을 선택합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/philipperemy/keras-tcn.git\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GDVR8gLO-ypY"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "qNGwcT82QzSB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqsvDog6T6_Z"
      },
      "source": [
        "**패딩의 주의점**\n",
        "\n",
        "\n",
        "패딩을 사용할 때 padding='post'는 시퀀스의 끝에 0을 추가하며, dtype='float32'는 모델이 요구하는 데이터 타입에 맞춰 설정해야 합니다. 또한, 패딩이 모델의 예측 성능에 영향을 줄 수 있으므로, TCN 같은 네트워크에서는 패딩이 성능에 미치는 영향을 주의 깊게 관찰할 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "OP0V4HkfgazZ",
        "outputId": "3d06075d-fe5e-48c7-fcd4-f893dee3c0cf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-7563a430c883>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모든 데이터셋에서 가장 긴 시퀀스 길이를 찾습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscaled_train_set\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscaled_validation_set\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscaled_test_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 데이터를 패딩하여 동일한 길이로 만듭니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscaled_train_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ],
      "source": [
        "# 모든 데이터셋에서 가장 긴 시퀀스 길이를 찾습니다.\n",
        "max_len = max([max(len(features), len(targets)) for features, targets in scaled_train_set + scaled_validation_set + scaled_test_set])\n",
        "\n",
        "# 데이터를 패딩하여 동일한 길이로 만듭니다.\n",
        "X_train_padded = np.array([np.pad(features.values, ((0, max_len - len(features)), (0, 0)), mode='constant') for features, _ in scaled_train_set])\n",
        "y_train_padded = np.array([np.pad(targets.values, (0, max_len - len(targets)), mode='constant') for _, targets in scaled_train_set])\n",
        "\n",
        "X_val_padded = np.array([np.pad(features.values, ((0, max_len - len(features)), (0, 0)), mode='constant') for features, _ in scaled_validation_set])\n",
        "y_val_padded = np.array([np.pad(targets.values, (0, max_len - len(targets)), mode='constant') for _, targets in scaled_validation_set])\n",
        "\n",
        "X_test_padded = np.array([np.pad(features.values, ((0, max_len - len(features)), (0, 0)), mode='constant') for features, _ in scaled_test_set])\n",
        "y_test_padded = np.array([np.pad(targets.values, (0, max_len - len(targets)), mode='constant') for _, targets in scaled_test_set])\n",
        "\n",
        "# 데이터의 형태 확인\n",
        "print(\"X_train_padded shape:\", X_train_padded.shape)\n",
        "print(\"y_train_padded shape:\", y_train_padded.shape)\n",
        "print(\"X_val_padded shape:\", X_val_padded.shape)\n",
        "print(\"y_val_padded shape:\", y_val_padded.shape)\n",
        "print(\"X_test_padded shape:\", X_test_padded.shape)\n",
        "print(\"y_test_padded shape:\", y_test_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c0o35WFmJ7i"
      },
      "outputs": [],
      "source": [
        "print(type(X_train_padded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnqsQ9Mzgogc"
      },
      "outputs": [],
      "source": [
        "# 결과 출력\n",
        "print(\"Padded X_train:\")\n",
        "print(X_train_padded)\n",
        "print(\"Padded y_train:\")\n",
        "print(y_train_padded)\n",
        "print(\"Padded X_val:\")\n",
        "print(X_val_padded)\n",
        "print(\"Padded y_val:\")\n",
        "print(y_val_padded)\n",
        "print(\"Padded X_test:\")\n",
        "print(X_test_padded)\n",
        "print(\"Padded y_test:\")\n",
        "print(y_test_padded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylv7AefREnMJ"
      },
      "source": [
        "**-모델 학습 및 최적화** : 선택한 모델을 훈련 데이터에 적용하여 학습시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD0wBXEBSmd0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "pip install keras-tcn  # TCN 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdkk4GBZhb0U"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1vMOco9kiUn"
      },
      "outputs": [],
      "source": [
        "# 모델 구성\n",
        "model = Sequential([\n",
        "    TCN(input_shape=(None, 5),  # 입력 시퀀스 길이는 가변적이며, 특성 수는 5\n",
        "        nb_filters=64,\n",
        "        kernel_size=3,  # 커널 사이즈는 3으로 설정\n",
        "        nb_stacks=1,\n",
        "        dilations=[1, 2, 4, 8, 16],\n",
        "        padding='causal',\n",
        "        use_skip_connections=True,\n",
        "        dropout_rate=0.2,  # 드롭아웃 추가\n",
        "        return_sequences=True,  # 시퀀스의 모든 타임 스텝에 대한 출력을 반환\n",
        "        activation='relu',\n",
        "        kernel_initializer='he_normal'),\n",
        "    Dense(1)  # 출력층은 하나의 값을 예측\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQtRCiNJnP2N"
      },
      "outputs": [],
      "source": [
        "# 모델 요약 출력\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZwjLoEHoLlq"
      },
      "outputs": [],
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])  # 평균 절대 오차도 추적"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4v05u6yqFaA"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "history = model.fit(X_train_padded, y_train_padded,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_padded, y_val_padded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYKSKah9qXkW"
      },
      "outputs": [],
      "source": [
        "# 학습 과정 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljcSXGwdwpNZ"
      },
      "outputs": [],
      "source": [
        "# 정규화된 훈련 데이터를 원래 스케일로 되돌리기\n",
        "def inverse_transform(y_pred, scaler):\n",
        "    y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
        "    return y_pred_rescaled\n",
        "\n",
        "# 오차율 계산 함수\n",
        "def calculate_error_rate(y_true, y_pred):\n",
        "    # 0으로 나누기 오류를 방지하기 위해 0인 경우에는 0을 반환하고, 그 외에는 오차율을 계산합니다.\n",
        "    mask = y_true != 0\n",
        "    if mask.any():\n",
        "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "    else:\n",
        "        return np.nan  # 0으로 나누기 오류가 발생한 경우에는 NaN을 반환합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iA2eUU_xB55"
      },
      "outputs": [],
      "source": [
        "# 모델을 사용하여 예측 수행\n",
        "y_pred_padded = model.predict(X_test_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4j3JaZ-1Pdd"
      },
      "outputs": [],
      "source": [
        "y_pred_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pMSEds24NB1"
      },
      "outputs": [],
      "source": [
        "y_test_padded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 계산된 오차율\n",
        "error_rate = calculate_error_rate(y_test_padded, y_pred_padded)\n",
        "\n",
        "# 결과값 출력\n",
        "print(f'Error Rate: {error_rate:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "id": "M3T8-LKbBx60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 역변환"
      ],
      "metadata": {
        "id": "3s1y6V2UAr78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9hrutAcxmDk"
      },
      "outputs": [],
      "source": [
        "# 오차율 계산\n",
        "error_rate = calculate_error_rate(y_true_rescaled, y_pred_rescaled)\n",
        "print(f'Error Rate: {error_rate:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuehows8Eq5b"
      },
      "source": [
        "# **5. 모델 평가 및 선택**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVpIHtz8EvLC"
      },
      "source": [
        "**-성능 평가** : MAE, RMSE, MAPE 등의 지표를 사용하여 모델의 예측 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zONFjrFcE5W0"
      },
      "source": [
        "# **6. 예측 및 결과 해석**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rY57hOE8W1"
      },
      "source": [
        "**-미래 예측**: 최종 모델을 사용하여 미래 값에 대한 예측을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eX6vdXbFZPs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHSXD3iGFB4c"
      },
      "source": [
        "**-결과 해석**: 예측 결과를 분석하고, 비즈니스 인사이트나 결정을 내리는 데 활용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR0AIHKuFZvs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
